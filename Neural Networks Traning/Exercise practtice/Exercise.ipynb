{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52d7170",
   "metadata": {},
   "source": [
    "# Problem Statement: **Training in Agricultural Company**\n",
    "\n",
    "### In this chapter, you’ll explore the foundational aspects of training neural networks in AI-oriented Agricultural company. You’ll work as an AI engineer to train models that solve critical challenges in different domains. Along the way, you’ll learn about gradient descent, batch processing, and training neural networks from scratch.\n",
    "\n",
    "References:\n",
    "* Column Stack (Numpy) [link](https://numpy.org/doc/stable/reference/generated/numpy.column_stack.html)\n",
    "\n",
    "* PyTorch Tensors (PyTorch) [link](https://pytorch.org/tutorials/beginner/introyt/tensors_deeper_tutorial.html)\n",
    "\n",
    "* Sequential (PyTorch) [link](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48585701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b321333d",
   "metadata": {},
   "source": [
    "### **Task1: Predicting Equipment Costs**\n",
    "\n",
    "The AI Agriculture Company is developing a tool to predict the cost of manufacturing its new agricultural equipment. The cost is directly proportional to the square of the material used. Your task is to compute and predict the cost, and debug the gradients of the implemented backpropagation process.\n",
    "\n",
    "Use when required: $$ f(x) = x^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50458a28",
   "metadata": {},
   "source": [
    "**Step1:** Define the Problem\n",
    "\n",
    "Assume the material required is represented as a single feature: **material_amount**. For simplicity:\n",
    "\n",
    "* **Input:** material_amount (a tensor of size (1, 1)) — e.g., 5 units of material.\n",
    "* **Target cost:** material_amount ** 2 — the cost of producing the equipment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7987c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Material amount as input (e.g., 5 units)\n",
    "material_amount = torch.tensor([[5.0]], requires_grad=False)\n",
    "\n",
    "# Target cost (cost = material_amount ** 2)\n",
    "target_cost = material_amount ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757cc241",
   "metadata": {},
   "source": [
    "**Step2:** Set Up the Model\n",
    "\n",
    "Use a single-layer linear model to predict the cost. The model should:\n",
    "\n",
    "* Take material_amount as input.\n",
    "* Output the predicted cost (scalar)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f1d0980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with random weights and zero biases\n",
    "torch.manual_seed(0)  # For reproducibility\n",
    "weight = torch.tensor([[0.5]], requires_grad=True)  # Initialize weight manually\n",
    "bias = torch.tensor([[0.0]], requires_grad=True)  # Initialize bias as zero\n",
    "\n",
    "predicted_cost = torch.matmul(material_amount, weight) + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb3273b",
   "metadata": {},
   "source": [
    "**Step3:** Compute Loss\n",
    "\n",
    "Use Mean Squared Error **(MSE)** to calculate the loss between the predicted and actual costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c666221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: Mean Squared Error (MSE)\n",
    "\n",
    "loss = torch.mean((predicted_cost-target_cost)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7b722f",
   "metadata": {},
   "source": [
    "**Step4:** Backpropagation\n",
    "\n",
    "* Write the gradient descent process step-by-step.\n",
    "* Manually compute the gradients of the loss with respect to the model's weights and biases using the chain rule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "015b0508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gradient of the loss w.r.t. predicted_cost\n",
    "grad_predicted_cost = 2 * (predicted_cost - target_cost) / target_cost.size(0)  # dL/d(predicted_cost)\n",
    "\n",
    "# Calculate the gradient of predicted_cost w.r.t. weight and bias\n",
    "grad_weight = torch.matmul(material_amount.T, grad_predicted_cost) # dL/d(weight)\n",
    "grad_bias = torch.sum(grad_predicted_cost)  # dL/d(bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ec9b9",
   "metadata": {},
   "source": [
    "**Step5:** Verify Gradients\n",
    "\n",
    "Use **torch.autograd** to compute gradients automatically and compare them with your manual calculations.\n",
    "\n",
    "You can use **allclose** to check whether all elements of two tensors are approximately equal, within a specified tolerance.\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.allclose.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d42bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "734b4548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Gradients:\n",
      "Weight Gradient: -225.0\n",
      "Bias Gradient: -45.0\n",
      "\n",
      "Autograd Gradients:\n",
      "Weight Gradient: -225.0\n",
      "Bias Gradient: -45.0\n",
      "\n",
      "Gradient Verification:\n",
      "Weight Gradients Match: True\n",
      "Bias Gradients Match: True\n"
     ]
    }
   ],
   "source": [
    "# Compare Gradients\n",
    "print(\"Manual Gradients:\")\n",
    "print(\"Weight Gradient:\", grad_weight.item())\n",
    "print(\"Bias Gradient:\", grad_bias.item())\n",
    "\n",
    "print(\"\\nAutograd Gradients:\")\n",
    "print(\"Weight Gradient:\", weight.grad.item())\n",
    "print(\"Bias Gradient:\", bias.grad.item())\n",
    "\n",
    "# Verify the Gradients\n",
    "print(\"\\nGradient Verification:\")\n",
    "print(\"Weight Gradients Match:\", torch.allclose(grad_weight, weight.grad, atol=1e-6))\n",
    "print(\"Bias Gradients Match:\", torch.allclose(grad_bias, bias.grad, atol=1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6776d85a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
